---
title: "BIOS_Applied_662_Power"
author: "Linran Zhou"
date: "7/18/2019"
output: html_document
---

```{r setup, include=FALSE}

```

##Power and Sample Size

###Power and Sample Size, Part I (Lecture 19)

To estimate sample size, we need to specify:

-Study design
-Significance level $\alpha$
-Null hypothesis
-Test statistic and its distribution
-Value $\theta_A$ that we want to detect, and the desired power to detect this value

-More complex models may require specifying other parameters, such as covariances

\textbf{Example}: One sample t-test (Lecture 19, Slide 16-27)

Suppose N=50, $\alpha$=0.05, $\sigma^2$=225 $|\mu_0-\mu_A|$=5

$H_0:\mu=\mu_0$ vs. $H_A:\mu=\mu_A \ne \mu_0$ 

Using t-test because in practice, $\sigma$ is not known

```{}
#By-hand in R

1-pt(qt(0.975,49),df=49,ncp=5*sqrt(50)/15)) 

  #qt with 50-1 degrees of freedom, and 1-alpha/2
  #ncp is the non-centrality parameter lambda, which is mu_A*sqrt(N)/sigma
  

#R function

power.t.test(n=50,sd=15,delta=5,type="one.sample")

#SAS

proc power;
  onesamplemeans
  mean = 5
  ntotal = 50
  stddev=15
  power=.;
run;


```

\textbf{Example}: One Sample Z-Test, Binary Outcome: Example (Lecture 19, Slide 28-33)

Want to calculate a sample size for a nominal power. If calculating by hand (see slide 28-29), round up typically

```{}
#SAS

proc power;
  onesamplefreq test=z
  method=normal
  nullproportion=0.02
  proportion=0.05
  power=0.9
  ntotal=.;
run;

```

\textbf{Example}: Exact Test, Binary Outcome (Lecture 19, Slides 32-33)


```{}

#In SAS

proc power;
  onesamplefreq test=exact
  method=exact
  nullproportion=0.2
  proportion=0.5
  power = .
  ntotal=20;
run;
```


###Power and Sample Size, Part 2 (Lecture 20)

\textbf{Example}: Two Sample Test: Continuous Outcome (Lecture 20, Slide 3-10)

-Ex: Compare two drugs for lowering cholesterol

$H_0: \mu_1=\mu_2$ vs. $H_A: \mu_1 \ne \mu_2$

\textbf{Assumptions}: Homogeneity of variance, variance known, normality/CLT

Formula by hand on Lecture 20, Slide 3 ==> This is N for each group, so multiply by 2 for total sample size

There are N observations in EACH group, so the total sample size is 2N

\textit{Unknown Variance}: Test statistic and distribution on Lecture 20, Slide 5

Assume $N_1=N_2=N$

```{}

#Two-Sample Test, variance unknown


#By-hand in R (Lecture 20, Slide 6)

1-pt(qt(0.975,116),116,15/25*sqrt(59/2))

  #116 is df = 2N-2

  #ncp=(mu1_mu2)/sigma*sqrt(N/2)
  

#Function in R (Lecture 20, Slide 6)

power.t.test(n=59,delta=15,sd=25)


#In SAS (Lecture 20, Slide 7)

proc power;
  twosamplemeans
  meandiff=15
  ntotal=118
  stddev=25
  power=.;
run;


#Calculating N, given the power (N is for a single group)

#In R (Lecture 20, Slide 9)

Given beta=0.1 and delta=0.5

power.t.test(power=0.9,delta=0.5)


#In SAS (Lecture 20, Slide 10)

proc power;
  twosamplemeans
  meandiff=15
  ntotal=.
  stddev=30
  power=0.9;
run;

```

\textbf{Example}: Two-Sample Test: Binary Outcome

Lecture 20, Slide 11 ==> Using SAS will give you a different answer than this because SAS 
uses a different approximation

```{}
#In SAS (Lecture 20, Slide 12-13)

proc power;
  twosamplefreq
  refp=0.2
  pdiff=0.0727
  ntotal= .
  power=0.9;
run;

#In R by hand (Lecture 20, Slide 19)

# sample size formula for comparing two
# binomial proportions based on Fleiss (second edition) page 41

ss_fleiss <- function(pi1,pi2,alpha,power){
q1 <- 1-pi1
q2 <- 1-pi2
pbar <- (pi1+pi2)/2
qbar <- 1-pbar
num <- qnorm(1-alpha/2)*sqrt(2*pbar*qbar)+qnorm(power)*sqrt(pi1*q1+pi2*q2)
den <- (pi2-pi1)
(num/den)^2
}

ss_fleiss(0.2,0.2727,0.05,0.9)

```

Lecture 20, Slides 21-35 for \textbf{Example}: Case-Control: Binary Exposure

\textbf{Simulated Power}


```{}

#Using R
#Lecture 20, Slide 41 (also on Homework 7, #2a)

set.seed(251) 
mu<-50
sd_x <-8 #Sd of X
sd_epsilon<-10 #Sd of epsilon
mysim <- function(n,nsims){#n is the sample size and nsims is the number of simulations
  rejects <- 0
  for (ii in 1:nsims){
    x <- rnorm(n,mu,sd_x) 
    mdiff<-0.2*x
    y <- rnorm(n,mdiff,sd_epsilon)
    lmd <- lm(y~x)
    z<-summary(lmd)$coefficients[8]
    if(z<0.05) rejects<-rejects+1 
  }
  print(paste("estimated power:",rejects/nsims))
}


#Using SAS (Lecture 20, Slide 42-43)

%macro epower(mdiff=,seed=);
  %let i=1; %let n=59; %let sd=25; %let nsims=10000;
  
  data;
    %do i = 1 %to &nsims;
      i=&i;
      do j=1 to &n; y=rannor(&seed)*&sd; group=1; output; end;
      do j=1 to &n; y=rannor(&seed)*&sd + &mdiff; group=2; output; end;
    %end;
  run;
  
  ods output ttests=ttests;
  proc ttest; 
    class group; 
    var y; 
    by i; 
  run;
  
  data ttests; 
    set ttests;
    if method="Pooled";
    reject=0; 
    if Probt<0.05 then reject=1;
  run;
  
  proc freq data=ttests; 
    table reject; 
  run;
%mend;

%epower(mdiff=15,seed=97231);



```

###Power and Sample Size, Part III (Lecture 21)

\textbf{Example}: Two-Sample T-test, Unbalanced designs

Assumptions: Normality/CLT and homogeneity of variance

```{}
#R, by hand (Lecture 21, Slide 5)

1-pt(qt(0.975,28),28,15/(25*sqrt(1/10+1/20)))

  #df = 28 = (10+20)-2
  #mu1-mu2 = 15
  #sigma=25
  #N1=10, N2=20
  
#By SAS (Lecture 21, Slide 6)

proc power;
  twosamplemeans
  meandiff=10|20
  stddev=25
  power=.;
run;


```

Remainder of lecture discusses adjusting for drop-outs and loss to follow-up (Lecture 21, Slides 7-11), then adjusting for covariates (Lecture 21, Slides 12-17)


